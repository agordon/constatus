Records a videofile when motion is detected via a camera.
This camera can be locally attached to your Linux system or be accessed via MJPEG.

Supports:
  input:
   - video4linux
   - MJPEG cameras
   - RTSP cameras
   - JPEG cameras

  output:
   - AVI file(s)
   - individual JPEGs
   - HTTP streaming
   - video4linux loopback device
   - via plugins

  motion detection
   - also via plugin so that you can easily use one from e.g. OpenCV

  filters:
   - add generic text
     two versions: fast (low CPU) or scaled (text can be any font, size or color)
   - boost contrast
   - convert to grayscale
   - add box around movement
   - mirror vertical and/or horizontal
   - neighbour average noise filter
   - picture overlay (with alpha blending)
   - filters plugins (.so-files that can be linked at runtime)


Required:
- libcurl
- libjansson
- libjpeg
- libpng
- libgwavi - from https://github.com/Rolinh/libgwavi.git
- libavformat / libswscale / libavcodec / libavutil
- libcairo
- libnetpbm10-dev


The program supports cameras that generate YUYV, JPEG, RGB or YUV420 output.
If your camera emits something different, e.g. P207 (PAC207) then you can use libv4l (by Hans de Goede).
E.g.:
LD_PRELOAD=/usr/lib/arm-linux-gnueabihf/libv4l/v4l2convert.so ./constatus -c constatus-v4l.conf (on the raspberry pi)
or
LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libv4lconvert.so ./constatus -c constatus-v4l.conf         (on x64)


The program is configured with a json-formatted file.
Take a look at the examples: constatus-jpeg.conf constatus-mjpeg.conf constatus-v4l.conf constatus-v4l-loopback.conf

Each configuration has 1 source. So if you want to monitor multiple cameras, then you need to start multiple instances of constatus. The idea is that if anything crashes, you won't loose all cameras.

A configuration can have 1 motion-trigger and 0 or more stream-to-file backends.

Most outputs (http, files, etc) and the motion-trigger can have 0 or more filters. Filters are executed in the order in which they are found on the configuration-file. You can also have multiple instances of the same filter for an output/motion-trigger.
Note that for source there are two lists of filters: before and after. The one in "before" are invoked before the motion-detection algorithm is invoked, the "after" is invoked when streaming to images to disk. Note that the ones in "before" should not e.g. add markers and such because that may influence the motion detection algorithm.

As said, constatus can have multiple streamers, filters, etc.; the only drawback is that it uses more cpu. Having available multiple cpus/cores/threads is an advantag for constatus.


(C) 2017 by Folkert van Heusden, released under AGPL v3.0
mail@vanheusden.com
